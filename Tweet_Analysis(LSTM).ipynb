{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet Analysis(LSTM).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmU3+HBLd0FVSzqHuRPbWz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Preranakh/DeepLearningProjects_Udemy/blob/main/Tweet_Analysis(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2ujg8x3-ssRA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout,LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "a=files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "mJGlUP40tXlJ",
        "outputId": "49f082f8-2ab5-4a32-e1bb-50ca0b3f4d45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c7bc05c9-4484-469b-a5e5-fb60e82e1b61\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c7bc05c9-4484-469b-a5e5-fb60e82e1b61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Corona_NLP_test.csv to Corona_NLP_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"Corona_NLP_test.csv\")"
      ],
      "metadata": {
        "id": "8N1phZLjtIZ8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sentiment']=LabelEncoder().fit_transform(data['Sentiment'])\n",
        "data=data.dropna(axis=1)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WFRHMz6GtsyZ",
        "outputId": "e2528ab2-558f-412d-b20b-59c216bb07c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dfbeba36-ce40-4c47-a646-397977ff6140\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>44953</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44954</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>44955</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>Find out how you can protect yourself and love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>44956</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>44957</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfbeba36-ce40-4c47-a646-397977ff6140')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfbeba36-ce40-4c47-a646-397977ff6140 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfbeba36-ce40-4c47-a646-397977ff6140');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   UserName  ...  Sentiment\n",
              "0         1  ...          0\n",
              "1         2  ...          4\n",
              "2         3  ...          1\n",
              "3         4  ...          2\n",
              "4         5  ...          3\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=data.drop('Sentiment',axis=1)\n",
        "y=data['Sentiment'].values\n",
        "y=y.reshape(-1,1)"
      ],
      "metadata": {
        "id": "BLfOlYUWtuLy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-og5AiOty6s",
        "outputId": "493bf70d-30bd-4723-d2f3-3a193398d077"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      UserName  ...                                      OriginalTweet\n",
              " 0            1  ...  TRENDING: New Yorkers encounter empty supermar...\n",
              " 1            2  ...  When I couldn't find hand sanitizer at Fred Me...\n",
              " 2            3  ...  Find out how you can protect yourself and love...\n",
              " 3            4  ...  #Panic buying hits #NewYork City as anxious sh...\n",
              " 4            5  ...  #toiletpaper #dunnypaper #coronavirus #coronav...\n",
              " ...        ...  ...                                                ...\n",
              " 3793      3794  ...  Meanwhile In A Supermarket in Israel -- People...\n",
              " 3794      3795  ...  Did you panic buy a lot of non-perishable item...\n",
              " 3795      3796  ...  Asst Prof of Economics @cconces was on @NBCPhi...\n",
              " 3796      3797  ...  Gov need to do somethings instead of biar je r...\n",
              " 3797      3798  ...  I and @ForestandPaper members are committed to...\n",
              " \n",
              " [3798 rows x 4 columns], array([[0],\n",
              "        [4],\n",
              "        [1],\n",
              "        ...,\n",
              "        [3],\n",
              "        [0],\n",
              "        [1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "message=x.copy()\n",
        "message.reset_index(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-TO5C3VtvLQ",
        "outputId": "ccfb16c0-b105-42c7-dc62-86cb4e3ca457"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps=PorterStemmer()\n",
        "corpus=[]\n",
        "for i in range(len(x)):\n",
        "  review=re.sub('[^a-zA-Z]',' ',message['OriginalTweet'][i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "  review=' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "voc_size=50000\n",
        "one_hot_r=[one_hot(word,voc_size) for word in corpus]\n",
        "\n",
        "sent_length=30\n",
        "input=pad_sequences(one_hot_r,padding='pre',maxlen=sent_length)\n",
        "\n",
        "final_input=np.array(input)\n",
        "final_output=np.array(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(final_input,final_output, test_size=0.33, random_state=42)\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUukgxHftIgE",
        "outputId": "c3ca2d81-f7fe-4826-808b-80ec8242e4c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2544, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "r5jwqb3BuTL6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(80))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train,y_train,batch_size=50,epochs=300,validation_data=(x_test,y_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezpTe0A5tNoW",
        "outputId": "d9456d8a-84d0-492b-fac0-4d2b7b3a9838"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "51/51 [==============================] - 5s 66ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 2/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 3/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 4/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 5/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 6/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 7/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 8/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 9/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 10/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 11/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 12/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 13/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 14/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 15/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 16/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 17/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 18/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 19/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 20/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 21/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 22/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 23/300\n",
            "51/51 [==============================] - 3s 52ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 24/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 25/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 26/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 27/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 28/300\n",
            "51/51 [==============================] - 4s 84ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 29/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 30/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 31/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 32/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 33/300\n",
            "51/51 [==============================] - 3s 52ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 34/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 35/300\n",
            "51/51 [==============================] - 4s 77ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 36/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 37/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 38/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 39/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 40/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 41/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 42/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 43/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 44/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 45/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 46/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 47/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 48/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 49/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 50/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 51/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 52/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 53/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 54/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 55/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 56/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 57/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 58/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 59/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 60/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 61/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 62/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 63/300\n",
            "51/51 [==============================] - 3s 52ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 64/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 65/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 66/300\n",
            "51/51 [==============================] - 3s 66ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 67/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 68/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 69/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 70/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 71/300\n",
            "51/51 [==============================] - 3s 53ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 72/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 73/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 74/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 75/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 76/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 77/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 78/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 79/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 80/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 81/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 82/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 83/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 84/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 85/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 86/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 87/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 88/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 89/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 90/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 91/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 92/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 93/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 94/300\n",
            "51/51 [==============================] - 3s 65ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 95/300\n",
            "51/51 [==============================] - 3s 68ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 96/300\n",
            "51/51 [==============================] - 4s 74ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 97/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 98/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 99/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 100/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 101/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 102/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 103/300\n",
            "51/51 [==============================] - 3s 65ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 104/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 105/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 106/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 107/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 108/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 109/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 110/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 111/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 112/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 113/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 114/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 115/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 116/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 117/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 118/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 119/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 120/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 121/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 122/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 123/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 124/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 125/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 126/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 127/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 128/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 129/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 130/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 131/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 132/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 133/300\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 134/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 135/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 136/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 137/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 138/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 139/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 140/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 141/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 142/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 143/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 144/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 145/300\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 146/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 147/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 148/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 149/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 150/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 151/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 152/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 153/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 154/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 155/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 156/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 157/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 158/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 159/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 160/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 161/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 162/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 163/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 164/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 165/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 166/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 167/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 168/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 169/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 170/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 171/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 172/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 173/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 174/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 175/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 176/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 177/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 178/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 179/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 180/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 181/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 182/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 183/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 184/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 185/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 186/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 187/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 188/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 189/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 190/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 191/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 192/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 193/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 194/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 195/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 196/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 197/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 198/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 199/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 200/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 201/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 202/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 203/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 204/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 205/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 206/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 207/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 208/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 209/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 210/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 211/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 212/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 213/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 214/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 215/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 216/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 217/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 218/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 219/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 220/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 221/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 222/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 223/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 224/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 225/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 226/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 227/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 228/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 229/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 230/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 231/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 232/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 233/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 234/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 235/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 236/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 237/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 238/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 239/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 240/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 241/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 242/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 243/300\n",
            "51/51 [==============================] - 3s 56ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 244/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 245/300\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 246/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 247/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 248/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 249/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 250/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 251/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 252/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 253/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 254/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 255/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 256/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 257/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 258/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 259/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 260/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 261/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 262/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 263/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 264/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 265/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 266/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 267/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 268/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 269/300\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 270/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 271/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 272/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 273/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 274/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 275/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 276/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 277/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 278/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 279/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 280/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 281/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 282/300\n",
            "51/51 [==============================] - 3s 62ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 283/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 284/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 285/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 286/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 287/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 288/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 289/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 290/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 291/300\n",
            "51/51 [==============================] - 3s 62ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 292/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 293/300\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 294/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 295/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 296/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 297/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 298/300\n",
            "51/51 [==============================] - 3s 62ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 299/300\n",
            "51/51 [==============================] - 3s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n",
            "Epoch 300/300\n",
            "51/51 [==============================] - 3s 59ms/step - loss: 0.0000e+00 - accuracy: 0.1521 - val_loss: 0.0000e+00 - val_accuracy: 0.1691\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff425eda50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "4732jwZTzwBq",
        "outputId": "10dba9ff-7a6d-42b4-dbad-f26a2f4324a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=model.predict(x_test) \n",
        "y_pred=np.argmax(a,axis=1)\n",
        "\n",
        "val=metrics.accuracy_score(y_test,y_pred)\n",
        "print(\"accuracy is =\",str(val*100)+\" %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj9Lo8T8wO2i",
        "outputId": "ee70b3f6-5b66-494e-80d4-8e0f62008268"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is = 16.188197767145134 %\n"
          ]
        }
      ]
    }
  ]
}